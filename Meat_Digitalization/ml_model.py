# ml_model.py
import os
from pathlib import Path
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import joblib

# === –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º –º–æ–¥–µ–ª–∏ ===
MODEL_PATH = Path("data") / "model.pkl"
SCALER_PATH = Path("data") / "scaler.pkl"
MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)

class MeatPHModel:
    """
    –ú–æ–¥–µ–ª—å –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è pH.
    –ü—Ä–æ—Å—Ç–∞—è –æ–±—ë—Ä—Ç–∫–∞ –Ω–∞–¥ LinearRegression + StandardScaler.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∑–∞–≥—Ä—É–∑–∫—É, –æ–±—É—á–µ–Ω–∏–µ, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è.
    """
    def __init__(self):
        self.model = None
        self.scaler = None
        self.feature_cols = []
        self._load_existing()

    # --- –∑–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –º–æ–¥–µ–ª–∏, –µ—Å–ª–∏ –µ—Å—Ç—å ---
    def _load_existing(self):
        if MODEL_PATH.exists() and SCALER_PATH.exists():
            try:
                self.model = joblib.load(MODEL_PATH)
                self.scaler = joblib.load(SCALER_PATH)
                print("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ —Ñ–∞–π–ª–∞.")
            except Exception as e:
                print("‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏:", e)
                self.model, self.scaler = None, None
        else:
            print("‚ÑπÔ∏è –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ ‚Äî –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –æ–±—É—á–µ–Ω–∏–µ.")

    # --- –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ ---
    def train(self, df: pd.DataFrame, target_col="pH", feature_cols=None, test_size=0.2, random_state=42):
        """
        –û–±—É—á–∞–µ—Ç –ª–∏–Ω–µ–π–Ω—É—é –º–æ–¥–µ–ª—å –Ω–∞ –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö —Å –∫–æ–ª–æ–Ω–∫–æ–π pH.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ RMSE, R¬≤ –∏ —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
        """
        df = df.copy()
        df = df.dropna(subset=[target_col])
        if df.empty:
            raise ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (–ø—É—Å—Ç–æ–π DataFrame)")

        # –≤—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        if feature_cols is None:
            feature_cols = df.select_dtypes(include=[float, int]).columns.tolist()
            feature_cols = [c for c in feature_cols if c != target_col]

        if not feature_cols:
            df["_const"] = 1.0
            feature_cols = ["_const"]

        X = df[feature_cols].astype(float)
        y = df[target_col].astype(float)

        # –∑–∞—â–∏—Ç–∞ –æ—Ç NaN –∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        X = X.replace([np.inf, -np.inf], np.nan).fillna(0)
        y = y.clip(lower=0.0, upper=14.0)

        self.scaler = StandardScaler()
        Xs = self.scaler.fit_transform(X)

        X_train, X_test, y_train, y_test = train_test_split(
            Xs, y, test_size=test_size, random_state=random_state
        )

        self.model = LinearRegression()
        self.model.fit(X_train, y_train)

        y_pred = self.model.predict(X_test)
        rmse = mean_squared_error(y_test, y_pred, squared=False)
        r2 = r2_score(y_test, y_pred)

        self.feature_cols = feature_cols

        # —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
        joblib.dump(self.model, MODEL_PATH)
        joblib.dump(self.scaler, SCALER_PATH)

        print(f"‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞. RMSE={rmse:.4f}, R¬≤={r2:.4f}")

        return {
            "rmse": float(rmse),
            "r2": float(r2),
            "n_train": int(len(X_train)),
            "n_test": int(len(X_test)),
            "features": feature_cols
        }

    # --- –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ ---
    def predict(self, df: pd.DataFrame, feature_cols=None):
        """
        –î–µ–ª–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è pH –¥–ª—è –¥–∞–Ω–Ω—ã—Ö.
        –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç 6.5 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.
        """
        if self.model is None or self.scaler is None:
            print("‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç—Å—è –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (6.5).")
            n = len(df) if df is not None else 1
            return np.array([6.5] * n)

        if feature_cols is None:
            feature_cols = df.select_dtypes(include=[float, int]).columns.tolist()
        if not feature_cols:
            X = np.ones((len(df), 1))
        else:
            X = df[feature_cols].astype(float).values

        X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)
        Xs = self.scaler.transform(X)
        preds = self.model.predict(Xs)
        preds = np.clip(preds, 0.0, 14.0)
        return preds

    # --- –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è ---
    def evaluate_on_df(self, df, target_col="pH"):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –Ω–∞ –ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–º DataFrame."""
        if self.model is None or self.scaler is None:
            return {"error": "–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞"}
        if target_col not in df.columns:
            return {"error": f"–í DataFrame –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ {target_col}"}

        feature_cols = [c for c in df.select_dtypes(include=[float, int]).columns if c != target_col]
        if not feature_cols:
            return {"error": "–ù–µ—Ç —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏"}

        X = df[feature_cols].astype(float)
        y_true = df[target_col].astype(float)
        y_pred = self.predict(df, feature_cols)

        rmse = mean_squared_error(y_true, y_pred, squared=False)
        r2 = r2_score(y_true, y_pred)
        return {"rmse": rmse, "r2": r2, "n": len(df)}

    def reset_model(self):
        """–£–¥–∞–ª—è–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∏ —Å–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ."""
        if MODEL_PATH.exists():
            MODEL_PATH.unlink()
        if SCALER_PATH.exists():
            SCALER_PATH.unlink()
        self.model, self.scaler = None, None
        print("üîÅ –ú–æ–¥–µ–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –∑–∞–Ω–æ–≤–æ (–∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã —É–¥–∞–ª–µ–Ω—ã).")
